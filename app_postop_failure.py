import pandas as pd
import numpy as np
import streamlit as st

from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier

st.set_page_config(page_title="Perioperative RF & Mortality â€” Prediction", layout="wide")
st.title("Perioperative Respiratory Failure & Mortality â€” Prediction")

# ---------------- Fixed config ----------------
DATASETS = {
    "Occurrence (RFPE)": {
        "csv": "train_occurence.csv",        # åˆ—å« group: normal / rfpe
        "target": "group",
        "label_map": {"normal": 0, "rfpe": 1},
        "positive_name": "RFPE"
    },
    "28-day mortality": {
        "csv": "train_28days.csv",           # åˆ—å« group: é€šå¸¸ä¸º 0/1
        "target": "group",
        "label_map": None,                    # è‹¥ä¸ºæ•°å­—åˆ™ç›´æ¥ç”¨ï¼›è‹¥ä¸ºå­—ç¬¦ä¸²åˆ™è‡ªåŠ¨ 0/1
        "positive_name": "28-day death"
    },
    "90-day mortality": {
        "csv": "train_90days.csv",           # åˆ—å« group: é€šå¸¸ä¸º 0/1
        "target": "group",
        "label_map": None,
        "positive_name": "90-day death"
    },
}
THRESHOLD = 0.5   # ç®€åŒ–ï¼šå›ºå®š 0.5

# ---------------- Helpers ----------------
@st.cache_resource(show_spinner=False)
def train_for_task(task_key: str):
    """Load CSV, build & fit a simple RF pipeline. Return (model, feature_names, defaults)."""
    cfg = DATASETS[task_key]
    df = pd.read_csv(cfg["csv"], index_col=0)

    if cfg["target"] not in df.columns:
        raise ValueError(f"Target column '{cfg['target']}' not found in {cfg['csv']}.")

    X = df.drop(columns=[cfg["target"]])
    y_raw = df[cfg["target"]]

    # ç»Ÿä¸€æ ‡ç­¾åˆ° 0/1
    if y_raw.dtype.kind in "iuf":
        y = (y_raw > 0).astype(int)
    else:
        # å¦‚æœæä¾›äº†æ˜¾å¼æ˜ å°„ï¼ˆå¦‚ normal/rfpeï¼‰ï¼Œä¼˜å…ˆä½¿ç”¨ï¼›å¦åˆ™å°è¯•è‡ªåŠ¨äºŒå€¼åŒ–
        if cfg["label_map"]:
            y = y_raw.map(cfg["label_map"]).astype(int)
        else:
            # å°†æœ€å¸¸è§çš„ä¸¤ä¸ªå–å€¼æ˜ å°„ä¸º 0/1ï¼ˆå­—å…¸åºæˆ–å‡ºç°é¢‘æ¬¡å†³å®šï¼‰
            vals = y_raw.dropna().unique().tolist()
            if len(vals) != 2:
                raise ValueError(f"Target in {cfg['csv']} must be binary; got: {vals}")
            mapping = {vals[0]: 0, vals[1]: 1}
            y = y_raw.map(mapping).astype(int)

    # è®­ç»ƒä¸€ä¸ªè½»é‡ RFï¼ˆæ ‘æ¨¡å‹å¯¹å°ºåº¦ä¸æ•æ„Ÿï¼Œä½†ä¿ç•™ StandardScaler ä¸å½±å“ï¼‰
    pipe = Pipeline([
        ("scaler", StandardScaler()),
        ("clf", RandomForestClassifier(
            n_estimators=500,
            max_depth=None,
            min_samples_leaf=1,
            random_state=42,
            n_jobs=-1,
        ))
    ])
    pipe.fit(X, y)

    # ç”¨è®­ç»ƒé›†çš„ä¸­ä½æ•°ä½œä¸ºé»˜è®¤å€¼
    defaults = X.median(numeric_only=True).to_dict()

    return pipe, list(X.columns), defaults

# ---------------- UI: Task switch ----------------
task = st.radio(
    "Select task",
    list(DATASETS.keys()),
    horizontal=True
)

# è®­ç»ƒæ‰€é€‰ä»»åŠ¡çš„æ¨¡å‹
try:
    model, feature_names, default_vals = train_for_task(task)
except Exception as e:
    st.error(f"Training failed: {e}")
    st.stop()

# ---------------- Inputs (5 columns per row) ----------------
st.subheader("Input variables")

vals = {}
cols = st.columns(5)
for i, f in enumerate(feature_names):
    col = cols[i % 5]
    with col:
        dv = float(default_vals.get(f, 0.0))
        vals[f] = st.number_input(f, value=dv, format="%.6f")
    if (i + 1) % 5 == 0 and (i + 1) < len(feature_names):
        cols = st.columns(5)

# ---------------- Predict ----------------
if st.button("Predict"):
    try:
        X_new = pd.DataFrame([vals], columns=feature_names)
        proba = float(model.predict_proba(X_new)[:, 1][0])
        pred  = int(proba >= THRESHOLD)
        pos_name = DATASETS[task]["positive_name"]

        st.markdown(f"**Probability of {pos_name}:** `{proba:.3f}`")
        st.markdown(f"**Predicted label:** {'ğŸŸ¥ Positive' if pred==1 else 'ğŸŸ© Negative'}")
    except Exception as e:
        st.error(f"Prediction failed: {e}")
